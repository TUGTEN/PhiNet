{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "9-AudPoXGcFx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "!wget https://www.dropbox.com/s/ic9ym6ckxq2lo6v/Dataset_Signature_Final.zip\n",
        "#!wget https://www.dropbox.com/s/0n2gxitm2tzxr1n/lightCNN_51_checkpoint.pth\n",
        "#!wget https://www.dropbox.com/s/9yd1yik7u7u3mse/light_cnn.py\n",
        "import zipfile\n",
        "sigtrain = zipfile.ZipFile('Dataset_Signature_Final.zip', mode='r')\n",
        "sigtrain.extractall()"
      ]
    },
    {
      "metadata": {
        "id": "kHS42ULdGdqa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision"
      ]
    },
    {
      "metadata": {
        "id": "_gysHrgGGkr6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "import os\n",
        "import cv2\n",
        "import random\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "import torch.nn.functional as F\n",
        "from PIL import Image\n",
        "import PIL\n",
        "\n",
        "from numpy.random import choice, shuffle\n",
        "from itertools import product, combinations, combinations_with_replacement, permutations\n",
        "\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms\n",
        "\n",
        "train_image_list = []\n",
        "test_image_list = []\n",
        "\n",
        "\n",
        "for root, dirs, files in os.walk('Dataset'):\n",
        "  #if (len(dirs) ==0 and off in root):   \n",
        "  if (len(dirs) ==0):\n",
        "    for root_sub, dirs_sub, files_sub in os.walk(root):\n",
        "      for file in files_sub:\n",
        "        if 'dataset4' not in root_sub:\n",
        "          train_image_list.append(os.path.join(root_sub,file).rstrip('\\n'))\n",
        "        else:\n",
        "          test_image_list.append(os.path.join(root_sub,file).rstrip('\\n'))\n",
        "\n",
        "train_image_list_x = []\n",
        "for i in list(set([re.split('/',image)[1] for image in train_image_list ])):\n",
        "#datasetx = random.choice(dataset)\n",
        "#index1 = dataset.index(datasetx)\n",
        "#for dataset_ in dataset:\n",
        "  train_image_list_x.append([image for image in train_image_list if i in image])\n",
        "  \n",
        "train_image_lis_dataset1 = train_image_list_x[0]\n",
        "train_image_lis_dataset2 = train_image_list_x[1]\n",
        "train_image_lis_dataset3 = train_image_list_x[2]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v-gjSPZIGoai",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PhiLoader(data.Dataset):\n",
        "  \n",
        "  def __init__(self, image_list, resize_shape, transform=True):\n",
        "    \n",
        "\n",
        "    self.image_list = image_list\n",
        "\n",
        "    self.diff = list(set([str(str(re.split('/',image)[-1]).split('.')[0])[-3:] for image in self.image_list]))\n",
        "    self.identity_image = []\n",
        "    \n",
        "    for i in self.diff:\n",
        "      self.identity_image.append([image for image in self.image_list if ((str(str(image).split('/')[-1]).split('.')[0]).endswith(i))])\n",
        "\n",
        "      \n",
        "    self.PairPool=[]\n",
        "    \n",
        "    for user in self.identity_image:\n",
        "      Real=[]\n",
        "      Forge=[]\n",
        "      for image in user:\n",
        "        if 'real' in image:\n",
        "          Real.append(image)\n",
        "\n",
        "        else:\n",
        "          Forge.append(image)\n",
        "          \n",
        "      self.PairPool.extend(list(product(Real,Forge+Real)))\n",
        " \n",
        "    self.Dimensions = resize_shape\n",
        "    self.transform=transform\n",
        "    self.labels=[]\n",
        "    self.ToGray=transforms.Grayscale()\n",
        "    self.RR=transforms.RandomRotation(degrees=10,resample=PIL.Image.CUBIC)\n",
        "    self.Identity = transforms.Lambda(lambda x : x)\n",
        "    self.RRC = transforms.Lambda(lambda x : self.RandomRCrop(x))\n",
        "    self.Transform=transforms.RandomChoice([self.RR,\n",
        "                                            self.RRC,\n",
        "                                            self.Identity\n",
        "                                           ])\n",
        "    self.T=transforms.ToTensor()\n",
        "    self.labels=[]\n",
        "    \n",
        "  def __len__(self):\n",
        "\n",
        "    return len(self.PairPool)\n",
        "  \n",
        "  def RandomRCrop(self,image):\n",
        "    width,height = image.size\n",
        "    size=random.uniform(0.9,1.00)\n",
        "    #ratio = random.uniform(0.45,0.55)\n",
        "    newheight = size*height\n",
        "    newwidth = size*width\n",
        "    T=transforms.RandomCrop((int(newheight),int(newwidth)))\n",
        "    return T(image)\n",
        "\n",
        "  \n",
        "  def __getitem__(self,index):\n",
        "    \n",
        "    #print(\"index\",index)\n",
        "    index=index%len(self.PairPool)\n",
        "    pairPool = self.PairPool[index]\n",
        "    \n",
        "    img1 = self.ToGray(Image.open(pairPool[0]))\n",
        "    img2 = self.ToGray(Image.open(pairPool[1]))  \n",
        "    \n",
        "    label_1 = pairPool[0].split('/')[2]\n",
        "    label_2 = pairPool[1].split('/')[2]\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "    if label_1 == label_2:              ### same class\n",
        "      l=0.0\n",
        "      self.labels.append(l)\n",
        "      \n",
        "    else:                               ### different class     \n",
        "      l=1.0\n",
        "      self.labels.append(l)\n",
        "      \n",
        "      \n",
        "    if self.transform:\n",
        "      img1 = self.Transform(img1)\n",
        "      img2 = self.Transform(img2) \n",
        "    \n",
        "    return self.T(img1.resize(self.Dimensions)), self.T(img2.resize(self.Dimensions)), torch.tensor(l)  \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M6L2gkQzHc7Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class PhiNet(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        super(PhiNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "                    nn.Conv2d(1,96,kernel_size=11,stride=1),\n",
        "                    nn.ReLU(),\n",
        "                    nn.LocalResponseNorm(5, alpha=1e-4, beta=0.75, k=2),\n",
        "                    nn.MaxPool2d(kernel_size=3, stride=2))\n",
        "  \n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "                    nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "                    nn.ReLU(),\n",
        "                    nn.LocalResponseNorm(5, alpha=1e-4, beta=0.75, k=2),\n",
        "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                    nn.Dropout2d(p=0.3))\n",
        "        \n",
        "        self.layer3 = nn.Sequential(\n",
        "                    nn.Conv2d(256,384, kernel_size=3, stride=1, padding=1))\n",
        "        \n",
        "        self.layer4 = nn.Sequential(\n",
        "                    nn.Conv2d(384,256, kernel_size=3, stride=1, padding=1),\n",
        "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                    nn.Dropout2d(p=0.3))\n",
        "        \n",
        "        self.layer5 = nn.Sequential(\n",
        "                    nn.Conv2d(256,128, kernel_size=3, stride=1, padding=1),\n",
        "                    nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "                    nn.Dropout2d(p=0.3))\n",
        "        \n",
        "        self.adap = nn.AdaptiveAvgPool3d((128,6,6))\n",
        "        \n",
        "        self.layer6 = nn.Sequential(\n",
        "                    nn.Linear(4608,512),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Dropout(p=0.5))\n",
        "        \n",
        "        \n",
        "        \n",
        "        self.layer7 = nn.Sequential(\n",
        "                    nn.Linear(512,128),\n",
        "                    nn.ReLU())\n",
        "        \n",
        "               \n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.adap(out)\n",
        "\n",
        "        out = out.reshape(out.size()[0], -1)\n",
        "        \n",
        "        \n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gNqcbrjnHpwx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def set_optimizer_lr(optimizer, lr):\n",
        "    # callback to set the learning rate in an optimizer, without rebuilding the whole optimizer\n",
        "    for param_group in optimizer.param_groups:\n",
        "        param_group['lr'] = lr\n",
        "    return optimizer\n",
        "  \n",
        "def se(initial_lr,iteration,epoch_per_cycle):\n",
        "  return initial_lr * (math.cos(math.pi * iteration / epoch_per_cycle) + 1) / 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pttS4-trHxFh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Contrastive loss function.\n",
        "    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +\n",
        "                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "\n",
        "\n",
        "        return loss_contrastive\n",
        "\n",
        "    \n",
        "def contrastive_loss():\n",
        "    return ContrastiveLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KKnDxjO3HzyC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def compute_accuracy_roc(predictions, labels):\n",
        "  \n",
        "  '''\n",
        " Compute ROC accuracy with a range of thresholds on distances.\n",
        " '''\n",
        "\n",
        "  dmax = np.max(predictions)\n",
        "\n",
        "  dmin = np.min(predictions)\n",
        "\n",
        "  nsame = np.sum(labels == 0)\n",
        "\n",
        "  ndiff = np.sum(labels == 1)\n",
        "  thresh=1.0\n",
        "\n",
        "  step = 0.01\n",
        "  max_acc = 0\n",
        "\n",
        "  for d in np.arange(dmin, dmax+step, step):\n",
        "       \n",
        "    \n",
        "    idx1 = predictions.ravel() <= d\n",
        "    idx2 = predictions.ravel() > d\n",
        "\n",
        "    tpr = float(np.sum(labels[idx1] == 0)) / nsame       \n",
        "    tnr = float(np.sum(labels[idx2] == 1)) / ndiff\n",
        "    acc = 0.5 * (tpr + tnr)       \n",
        "    \n",
        "\n",
        "    if (acc > max_acc):\n",
        "      \n",
        "      max_acc = acc\n",
        "      thresh=d\n",
        "\n",
        "  return max_acc,thresh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HN-rUyTAH2jA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainloader1 = torch.utils.data.DataLoader(PhiLoader(image_list = train_image_lis_dataset1, resize_shape=[128,64]), \n",
        "                                                             batch_size=32, num_workers=4, shuffle = True, pin_memory=False)\n",
        "\n",
        "trainloader1_hr = torch.utils.data.DataLoader(PhiLoader(image_list = train_image_lis_dataset1, resize_shape=[256,128]), \n",
        "                                                             batch_size=16, num_workers=4, shuffle = True, pin_memory=False)\n",
        "\n",
        "trainloader1_uhr = torch.utils.data.DataLoader(PhiLoader(image_list = train_image_lis_dataset1, resize_shape=[512,256]), \n",
        "                                                             batch_size=4, num_workers=0, shuffle = False, pin_memory=False)\n",
        "\n",
        "trainloader3 = torch.utils.data.DataLoader(PhiLoader(image_list = train_image_lis_dataset3, resize_shape=[512,256]), \n",
        "                                                             batch_size=32, num_workers=1, shuffle = False, pin_memory=False)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(PhiLoader(image_list = test_image_list, resize_shape=[256,128]), \n",
        "                                                             batch_size=32, num_workers=1, shuffle = True, pin_memory=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sM_9ZdhsIJK-",
        "colab_type": "code",
        "outputId": "e1703276-bd94-49ea-f0e2-7289d23dbca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "print(device)\n",
        "best_loss = 99999999\n",
        "\n",
        "phinet = PhiNet().to(device)\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ebz_S1C1IiMN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "siamese_loss = contrastive_loss() ### Notice a new loss. contrastive_loss function is defined above.\n",
        "siamese_loss = siamese_loss.to(device)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UchREp25chxq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(epoch):\n",
        "  \n",
        "    global best_loss\n",
        "    phinet.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 1\n",
        "    \n",
        "    \n",
        "    for batch_idx, (inputs_1, inputs_2, targets) in enumerate(testloader):\n",
        "      \n",
        "      with torch.no_grad():\n",
        "        \n",
        "        inputs_1, inputs_2, targets = inputs_1.to(device), inputs_2.to(device), targets.to(device)\n",
        "        \n",
        "        features_1 = phinet(inputs_1)    ### get feature for image_1\n",
        "        features_2 = phinet(inputs_2)      ### get feature for image_2      \n",
        "        \n",
        "        loss = siamese_loss(features_1, features_2, targets.float())\n",
        "        test_loss += loss.item()\n",
        "        \n",
        "\n",
        "    # Save checkpoint.\n",
        "    losss = test_loss/len(testloader)\n",
        "    if  losss < best_loss:   ### save model with the best loss so far\n",
        "        print('Saving..') \n",
        "        state = {\n",
        "            'net': phinet\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, 'checkpoint/phinet_siamese.stdt')\n",
        "        best_loss = losss\n",
        "    \n",
        "    return test_loss/len(testloader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MwEudBr4JJDt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_se(epochs_per_cycle,initial_lr,dl):\n",
        "    phinet.train()\n",
        "    snapshots = []\n",
        "    global epoch;\n",
        "    epoch_loss=0\n",
        "    cycle_loss=0\n",
        "    global optimizer \n",
        "\n",
        "    for j in range(epochs_per_cycle):\n",
        "        epoch_loss = 0\n",
        "        print('\\nEpoch: %d' % epoch)\n",
        "        lr = se(initial_lr, j, epochs_per_cycle)\n",
        "        optimizer = set_optimizer_lr(optimizer, lr)\n",
        "        train = trainloader1\n",
        "\n",
        "        for batch_idx, (inputs_1, inputs_2, targets) in enumerate(train):\n",
        "\n",
        "            inputs_1, inputs_2, targets = inputs_1.to(device), inputs_2.to(device), targets.to(device)\n",
        " \n",
        "            optimizer.zero_grad()\n",
        "            features_1 = phinet(inputs_1)    ### get feature for image_1\n",
        "            features_2 = phinet(inputs_2)  \n",
        "\n",
        "            loss =siamese_loss(features_1, features_2, targets) \n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            epoch_loss += loss.item()/len(train)\n",
        "            \n",
        "\n",
        "        epoch+=1\n",
        "        cycle_loss += epoch_loss/(epochs_per_cycle)\n",
        "        print (\"e_Loss:\",epoch_loss);  \n",
        "\n",
        "    print(\"c_loss:\",cycle_loss)\n",
        "    snapshots.append(phinet.state_dict())\n",
        "  \n",
        "    return snapshots"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oPlBpUSQJzZG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "lr=1e-4\n",
        "epoch=0\n",
        "optimizer = optim.SGD(phinet.parameters(),lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XdPPINoFJ8uy",
        "colab_type": "code",
        "outputId": "804fc54e-da39-472b-c5e5-0b4410b6b51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        }
      },
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  train_se(3,lr,trainloader1)\n",
        "  test_loss = test(i)\n",
        "  print(\"Test Loss: \", test_loss)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch: 0\n",
            "e_Loss: 1.8136854987395439\n",
            "\n",
            "Epoch: 1\n",
            "e_Loss: 1.8160580522135685\n",
            "\n",
            "Epoch: 2\n",
            "e_Loss: 1.8135544312627692\n",
            "c_loss: 1.8144326607386272\n",
            "Saving..\n",
            "Test Loss:  1.9583299776603436\n",
            "\n",
            "Epoch: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:241: UserWarning: Couldn't retrieve source code for container of type PhiNet. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "e_Loss: 1.8022973537445073\n",
            "\n",
            "Epoch: 4\n",
            "e_Loss: 1.8116473335968817\n",
            "\n",
            "Epoch: 5\n",
            "e_Loss: 1.8046352110410988\n",
            "c_loss: 1.8061932994608294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cXHPFPGqdu0d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(6):\n",
        "  train_se(3,lr,trainloader1_hr)\n",
        "  test_loss = test(i)\n",
        "  print(\"Test Loss: \", test_loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gh94sM8WKN5U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loaded=torch.load('checkpoint/phinet_siamese.stdt')['net']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jHsKHzD6XIuQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gc\n",
        "def predict(model,dataloader,fn):\n",
        "  model.eval()\n",
        "  model.cuda()\n",
        "  labels=[]\n",
        "  out=[]\n",
        "  pwd = torch.nn.PairwiseDistance(p=1)\n",
        "  for x0,x1,label in dataloader:\n",
        "    \n",
        "    labels.extend(label.numpy())\n",
        "    a=model(x0.cuda())\n",
        "    b=model(x1.cuda())\n",
        "    #print(torch.log(a/(1-a)),a)\n",
        "    out.extend(pwd(a,b))\n",
        "    #!nvidia-smi\n",
        "    \n",
        "\n",
        "    \n",
        "  return fn(np.asarray(out),np.asarray(labels))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dtKUnPZuXL-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "testloader_ = torch.utils.data.DataLoader(PhiLoader(image_list = train_image_lis_dataset2, resize_shape=[256,128]), \n",
        "                                                             batch_size=16, num_workers=0, shuffle = False, pin_memory=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "  maxacc,threshold  = predict(loaded,testloader_,compute_accuracy_roc)\n",
        "  print(\"Accuracy:{:0.3f}\".format(maxacc*100),\"Threshold:{:0.3f}\".format(threshold))\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dag7LluAXS_D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}